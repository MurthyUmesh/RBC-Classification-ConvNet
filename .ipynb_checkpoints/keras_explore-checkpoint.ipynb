{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: GeForce GTX TITAN X (CNMeM is disabled, cuDNN 5103)\n",
      "/home/Devansh/anaconda2/lib/python2.7/site-packages/theano/sandbox/cuda/__init__.py:600: UserWarning: Your cuDNN version is more recent than the one Theano officially supports. If you see any problems, try updating Theano or downgrading cuDNN to version 5.\n",
      "  warnings.warn(warn)\n",
      "/home/Devansh/anaconda2/lib/python2.7/site-packages/theano/tensor/signal/downsample.py:6: UserWarning: downsample module has been moved to the theano.tensor.signal.pool module.\n",
      "  \"downsample module has been moved to the theano.tensor.signal.pool module.\")\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import lasagne\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "import os\n",
    "import time\n",
    "import plac\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import hickle\n",
    "import sklearn.cross_validation\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import skimage.transform\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "from keras.models import Sequential\n",
    "from keras.models import load_model\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.models import load_model\n",
    "from keras import backend as K\n",
    "from keras.utils.visualize_util import plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CW_DIR = os.getcwd()\n",
    "DATA_DIR = CW_DIR + '/data/'\n",
    "OUTPUT_DIR = CW_DIR + '/output/'\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "NUM_CLASSES = 10\n",
    "IMAGE_W = 70\n",
    "NUM_CHANNELS = 3\n",
    "\n",
    "NUM_EPOCHS = 250\n",
    "BATCH_SIZE = 32\n",
    "LEARNING_RATE = 0.0001\n",
    "MOMENTUM = 0.9\n",
    "\n",
    "np.random.seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_data_sampler(dataset, train):\n",
    "\n",
    "    # load in hickle dataset containing cell label dataset\n",
    "    d = hickle.load('{}/{}.hkl'.format(DATA_DIR, dataset))\n",
    "\n",
    "    GROUPS = {\n",
    "        'NORMAL': 0,\n",
    "        'Echinocyte': 1,\n",
    "        'Dacrocyte': 2,\n",
    "        'Schistocyte': 3,\n",
    "        'Elliptocyte': 4,\n",
    "        'Acanthocyte': 5,\n",
    "        'Target cell': 6,\n",
    "        'Stomatocyte': 7,\n",
    "        'Spherocyte': 8,\n",
    "        'Overlap' : 9\n",
    "    }\n",
    "\n",
    "    labels = []\n",
    "    images = []\n",
    "    for y, x in zip(d['y'], d['X']):\n",
    "        labels.append(GROUPS[y])\n",
    "        images.append(x)\n",
    "    labels = np.array(labels)\n",
    "    images = np.array(images)\n",
    "\n",
    "    sss = sklearn.cross_validation.StratifiedShuffleSplit(\n",
    "        labels,\n",
    "        n_iter=1,\n",
    "        test_size=0.2,\n",
    "        random_state=RANDOM_SEED,\n",
    "    )\n",
    "    if train:\n",
    "        ix, _ = tuple(sss)[0]\n",
    "    else:\n",
    "        _, ix = tuple(sss)[0]\n",
    "\n",
    "    labels = labels[ix]\n",
    "    images = images[ix]\n",
    "    \n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_images, train_labels = get_data_sampler(\"September_1_total_non_overlap\", train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images = train_images.transpose((0,3,1,2))\n",
    "enc = OneHotEncoder()\n",
    "enc.fit(train_labels[:,None])\n",
    "train_labels2=enc.transform(train_labels[:,None]).toarray()\n",
    "train_images.shape\n",
    "train_labels2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO (theano.gof.compilelock): Refreshing lock /home/Devansh/.theano/compiledir_Linux-3.16--generic-x86_64-with-debian-jessie-sid-x86_64-2.7.12-64/lock_dir/lock\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2690 samples, validate on 299 samples\n",
      "Epoch 1/50\n",
      "2690/2690 [==============================] - 4s - loss: 2.1865 - acc: 0.2335 - categorical_accuracy: 0.2335 - mean_squared_error: 0.0864 - val_loss: 2.0883 - val_acc: 0.2977 - val_categorical_accuracy: 0.2977 - val_mean_squared_error: 0.0854\n",
      "Epoch 2/50\n",
      "2690/2690 [==============================] - 4s - loss: 2.0035 - acc: 0.2565 - categorical_accuracy: 0.2565 - mean_squared_error: 0.0838 - val_loss: 2.1016 - val_acc: 0.3144 - val_categorical_accuracy: 0.3144 - val_mean_squared_error: 0.0856\n",
      "Epoch 3/50\n",
      "2690/2690 [==============================] - 4s - loss: 1.9139 - acc: 0.3193 - categorical_accuracy: 0.3193 - mean_squared_error: 0.0805 - val_loss: 1.7364 - val_acc: 0.4281 - val_categorical_accuracy: 0.4281 - val_mean_squared_error: 0.0700\n",
      "Epoch 4/50\n",
      "2690/2690 [==============================] - 4s - loss: 1.5430 - acc: 0.5186 - categorical_accuracy: 0.5186 - mean_squared_error: 0.0651 - val_loss: 1.5652 - val_acc: 0.5351 - val_categorical_accuracy: 0.5351 - val_mean_squared_error: 0.0661\n",
      "Epoch 5/50\n",
      "2690/2690 [==============================] - 4s - loss: 1.3624 - acc: 0.5781 - categorical_accuracy: 0.5781 - mean_squared_error: 0.0589 - val_loss: 1.3314 - val_acc: 0.6120 - val_categorical_accuracy: 0.6120 - val_mean_squared_error: 0.0571\n",
      "Epoch 6/50\n",
      "2690/2690 [==============================] - 4s - loss: 1.1955 - acc: 0.6227 - categorical_accuracy: 0.6227 - mean_squared_error: 0.0526 - val_loss: 1.1110 - val_acc: 0.6823 - val_categorical_accuracy: 0.6823 - val_mean_squared_error: 0.0452\n",
      "Epoch 7/50\n",
      "2690/2690 [==============================] - 4s - loss: 1.1200 - acc: 0.6498 - categorical_accuracy: 0.6498 - mean_squared_error: 0.0495 - val_loss: 1.0667 - val_acc: 0.6555 - val_categorical_accuracy: 0.6555 - val_mean_squared_error: 0.0458\n",
      "Epoch 8/50\n",
      "2690/2690 [==============================] - 4s - loss: 0.9850 - acc: 0.6822 - categorical_accuracy: 0.6822 - mean_squared_error: 0.0444 - val_loss: 0.8725 - val_acc: 0.7358 - val_categorical_accuracy: 0.7358 - val_mean_squared_error: 0.0376\n",
      "Epoch 9/50\n",
      "2690/2690 [==============================] - 4s - loss: 0.8621 - acc: 0.7152 - categorical_accuracy: 0.7152 - mean_squared_error: 0.0397 - val_loss: 0.8516 - val_acc: 0.7458 - val_categorical_accuracy: 0.7458 - val_mean_squared_error: 0.0375\n",
      "Epoch 10/50\n",
      "2690/2690 [==============================] - 4s - loss: 0.7910 - acc: 0.7524 - categorical_accuracy: 0.7524 - mean_squared_error: 0.0364 - val_loss: 0.8286 - val_acc: 0.7559 - val_categorical_accuracy: 0.7559 - val_mean_squared_error: 0.0348\n",
      "Epoch 11/50\n",
      "2690/2690 [==============================] - 4s - loss: 0.6929 - acc: 0.7729 - categorical_accuracy: 0.7729 - mean_squared_error: 0.0325 - val_loss: 0.6730 - val_acc: 0.7993 - val_categorical_accuracy: 0.7993 - val_mean_squared_error: 0.0287\n",
      "Epoch 12/50\n",
      "2690/2690 [==============================] - 4s - loss: 0.5992 - acc: 0.8089 - categorical_accuracy: 0.8089 - mean_squared_error: 0.0277 - val_loss: 0.5981 - val_acc: 0.8462 - val_categorical_accuracy: 0.8462 - val_mean_squared_error: 0.0243\n",
      "Epoch 13/50\n",
      "2690/2690 [==============================] - 4s - loss: 0.5181 - acc: 0.8431 - categorical_accuracy: 0.8431 - mean_squared_error: 0.0238 - val_loss: 0.5413 - val_acc: 0.8194 - val_categorical_accuracy: 0.8194 - val_mean_squared_error: 0.0246\n",
      "Epoch 14/50\n",
      "2690/2690 [==============================] - 4s - loss: 0.4412 - acc: 0.8665 - categorical_accuracy: 0.8665 - mean_squared_error: 0.0205 - val_loss: 0.4911 - val_acc: 0.8629 - val_categorical_accuracy: 0.8629 - val_mean_squared_error: 0.0206\n",
      "Epoch 15/50\n",
      "2690/2690 [==============================] - 4s - loss: 0.4539 - acc: 0.8613 - categorical_accuracy: 0.8613 - mean_squared_error: 0.0212 - val_loss: 0.4919 - val_acc: 0.8629 - val_categorical_accuracy: 0.8629 - val_mean_squared_error: 0.0203\n",
      "Epoch 16/50\n",
      "2690/2690 [==============================] - 4s - loss: 0.3765 - acc: 0.8862 - categorical_accuracy: 0.8862 - mean_squared_error: 0.0175 - val_loss: 0.4595 - val_acc: 0.8796 - val_categorical_accuracy: 0.8796 - val_mean_squared_error: 0.0183\n",
      "Epoch 17/50\n",
      "2690/2690 [==============================] - 4s - loss: 0.3455 - acc: 0.8866 - categorical_accuracy: 0.8866 - mean_squared_error: 0.0163 - val_loss: 0.4871 - val_acc: 0.8595 - val_categorical_accuracy: 0.8595 - val_mean_squared_error: 0.0204\n",
      "Epoch 18/50\n",
      "2690/2690 [==============================] - 4s - loss: 0.3128 - acc: 0.9004 - categorical_accuracy: 0.9004 - mean_squared_error: 0.0148 - val_loss: 0.4518 - val_acc: 0.8930 - val_categorical_accuracy: 0.8930 - val_mean_squared_error: 0.0173\n",
      "Epoch 19/50\n",
      "2690/2690 [==============================] - 4s - loss: 0.2612 - acc: 0.9175 - categorical_accuracy: 0.9175 - mean_squared_error: 0.0125 - val_loss: 0.5019 - val_acc: 0.8863 - val_categorical_accuracy: 0.8863 - val_mean_squared_error: 0.0177\n",
      "Epoch 20/50\n",
      "2690/2690 [==============================] - 4s - loss: 0.2769 - acc: 0.9115 - categorical_accuracy: 0.9115 - mean_squared_error: 0.0134 - val_loss: 0.6884 - val_acc: 0.8829 - val_categorical_accuracy: 0.8829 - val_mean_squared_error: 0.0213\n",
      "Epoch 21/50\n",
      "2690/2690 [==============================] - 4s - loss: 0.2689 - acc: 0.9223 - categorical_accuracy: 0.9223 - mean_squared_error: 0.0129 - val_loss: 0.4487 - val_acc: 0.8930 - val_categorical_accuracy: 0.8930 - val_mean_squared_error: 0.0167\n",
      "Epoch 22/50\n",
      "2690/2690 [==============================] - 4s - loss: 0.2197 - acc: 0.9234 - categorical_accuracy: 0.9234 - mean_squared_error: 0.0110 - val_loss: 0.4377 - val_acc: 0.8696 - val_categorical_accuracy: 0.8696 - val_mean_squared_error: 0.0188\n",
      "Epoch 23/50\n",
      "2690/2690 [==============================] - 4s - loss: 0.2270 - acc: 0.9238 - categorical_accuracy: 0.9238 - mean_squared_error: 0.0113 - val_loss: 0.4780 - val_acc: 0.8963 - val_categorical_accuracy: 0.8963 - val_mean_squared_error: 0.0168\n",
      "Epoch 24/50\n",
      "2690/2690 [==============================] - 4s - loss: 0.1911 - acc: 0.9394 - categorical_accuracy: 0.9394 - mean_squared_error: 0.0093 - val_loss: 0.5720 - val_acc: 0.8796 - val_categorical_accuracy: 0.8796 - val_mean_squared_error: 0.0194\n",
      "Epoch 25/50\n",
      "2690/2690 [==============================] - 4s - loss: 0.2615 - acc: 0.9115 - categorical_accuracy: 0.9115 - mean_squared_error: 0.0134 - val_loss: 0.4316 - val_acc: 0.8863 - val_categorical_accuracy: 0.8863 - val_mean_squared_error: 0.0177\n",
      "Epoch 26/50\n",
      "2690/2690 [==============================] - 4s - loss: 0.1897 - acc: 0.9398 - categorical_accuracy: 0.9398 - mean_squared_error: 0.0095 - val_loss: 0.5624 - val_acc: 0.9064 - val_categorical_accuracy: 0.9064 - val_mean_squared_error: 0.0170\n",
      "Epoch 27/50\n",
      "2690/2690 [==============================] - 4s - loss: 0.1756 - acc: 0.9383 - categorical_accuracy: 0.9383 - mean_squared_error: 0.0087 - val_loss: 0.4155 - val_acc: 0.9164 - val_categorical_accuracy: 0.9164 - val_mean_squared_error: 0.0147\n",
      "Epoch 28/50\n",
      "2690/2690 [==============================] - 4s - loss: 0.1699 - acc: 0.9513 - categorical_accuracy: 0.9513 - mean_squared_error: 0.0081 - val_loss: 0.4040 - val_acc: 0.8963 - val_categorical_accuracy: 0.8963 - val_mean_squared_error: 0.0166\n",
      "Epoch 29/50\n",
      "2690/2690 [==============================] - 4s - loss: 0.1616 - acc: 0.9457 - categorical_accuracy: 0.9457 - mean_squared_error: 0.0083 - val_loss: 0.4879 - val_acc: 0.8997 - val_categorical_accuracy: 0.8997 - val_mean_squared_error: 0.0163\n",
      "Epoch 30/50\n",
      "2690/2690 [==============================] - 4s - loss: 0.1672 - acc: 0.9454 - categorical_accuracy: 0.9454 - mean_squared_error: 0.0081 - val_loss: 0.4308 - val_acc: 0.8930 - val_categorical_accuracy: 0.8930 - val_mean_squared_error: 0.0170\n",
      "Epoch 31/50\n",
      "2690/2690 [==============================] - 4s - loss: 0.1210 - acc: 0.9569 - categorical_accuracy: 0.9569 - mean_squared_error: 0.0062 - val_loss: 0.5057 - val_acc: 0.9030 - val_categorical_accuracy: 0.9030 - val_mean_squared_error: 0.0166\n",
      "Epoch 32/50\n",
      "2690/2690 [==============================] - 4s - loss: 0.1369 - acc: 0.9569 - categorical_accuracy: 0.9569 - mean_squared_error: 0.0065 - val_loss: 0.4277 - val_acc: 0.9030 - val_categorical_accuracy: 0.9030 - val_mean_squared_error: 0.0156\n",
      "Epoch 33/50\n",
      "2690/2690 [==============================] - 4s - loss: 0.1330 - acc: 0.9558 - categorical_accuracy: 0.9558 - mean_squared_error: 0.0066 - val_loss: 0.5317 - val_acc: 0.8896 - val_categorical_accuracy: 0.8896 - val_mean_squared_error: 0.0185\n",
      "Epoch 34/50\n",
      "2690/2690 [==============================] - 4s - loss: 0.1213 - acc: 0.9606 - categorical_accuracy: 0.9606 - mean_squared_error: 0.0058 - val_loss: 0.4440 - val_acc: 0.9030 - val_categorical_accuracy: 0.9030 - val_mean_squared_error: 0.0152\n",
      "Epoch 35/50\n",
      "2690/2690 [==============================] - 4s - loss: 0.1360 - acc: 0.9546 - categorical_accuracy: 0.9546 - mean_squared_error: 0.0069 - val_loss: 0.4078 - val_acc: 0.8896 - val_categorical_accuracy: 0.8896 - val_mean_squared_error: 0.0162\n",
      "Epoch 36/50\n",
      "2690/2690 [==============================] - 4s - loss: 0.1299 - acc: 0.9561 - categorical_accuracy: 0.9561 - mean_squared_error: 0.0066 - val_loss: 0.3888 - val_acc: 0.9030 - val_categorical_accuracy: 0.9030 - val_mean_squared_error: 0.0145\n",
      "Epoch 37/50\n",
      "2690/2690 [==============================] - 4s - loss: 0.1003 - acc: 0.9677 - categorical_accuracy: 0.9677 - mean_squared_error: 0.0050 - val_loss: 0.6321 - val_acc: 0.9030 - val_categorical_accuracy: 0.9030 - val_mean_squared_error: 0.0164\n",
      "Epoch 38/50\n",
      "2690/2690 [==============================] - 4s - loss: 0.1178 - acc: 0.9647 - categorical_accuracy: 0.9647 - mean_squared_error: 0.0056 - val_loss: 0.5482 - val_acc: 0.8763 - val_categorical_accuracy: 0.8763 - val_mean_squared_error: 0.0193\n",
      "Epoch 39/50\n",
      "2690/2690 [==============================] - 4s - loss: 0.0892 - acc: 0.9721 - categorical_accuracy: 0.9721 - mean_squared_error: 0.0043 - val_loss: 0.5980 - val_acc: 0.8997 - val_categorical_accuracy: 0.8997 - val_mean_squared_error: 0.0184\n",
      "Epoch 40/50\n",
      "2690/2690 [==============================] - 4s - loss: 0.1081 - acc: 0.9680 - categorical_accuracy: 0.9680 - mean_squared_error: 0.0051 - val_loss: 0.4659 - val_acc: 0.9030 - val_categorical_accuracy: 0.9030 - val_mean_squared_error: 0.0160\n",
      "Epoch 41/50\n",
      "2690/2690 [==============================] - 4s - loss: 0.1125 - acc: 0.9632 - categorical_accuracy: 0.9632 - mean_squared_error: 0.0055 - val_loss: 0.6974 - val_acc: 0.8729 - val_categorical_accuracy: 0.8729 - val_mean_squared_error: 0.0207\n",
      "Epoch 42/50\n",
      "2690/2690 [==============================] - 4s - loss: 0.1303 - acc: 0.9565 - categorical_accuracy: 0.9565 - mean_squared_error: 0.0066 - val_loss: 0.6642 - val_acc: 0.8796 - val_categorical_accuracy: 0.8796 - val_mean_squared_error: 0.0193\n",
      "Epoch 43/50\n",
      "2690/2690 [==============================] - 4s - loss: 0.0908 - acc: 0.9743 - categorical_accuracy: 0.9743 - mean_squared_error: 0.0042 - val_loss: 0.6599 - val_acc: 0.8863 - val_categorical_accuracy: 0.8863 - val_mean_squared_error: 0.0180\n",
      "Epoch 44/50\n",
      "2690/2690 [==============================] - 4s - loss: 0.1318 - acc: 0.9587 - categorical_accuracy: 0.9587 - mean_squared_error: 0.0064 - val_loss: 0.5547 - val_acc: 0.8796 - val_categorical_accuracy: 0.8796 - val_mean_squared_error: 0.0180\n",
      "Epoch 45/50\n",
      "2690/2690 [==============================] - 4s - loss: 0.1375 - acc: 0.9572 - categorical_accuracy: 0.9572 - mean_squared_error: 0.0066 - val_loss: 0.5072 - val_acc: 0.8997 - val_categorical_accuracy: 0.8997 - val_mean_squared_error: 0.0166\n",
      "Epoch 46/50\n",
      "2690/2690 [==============================] - 4s - loss: 0.0795 - acc: 0.9740 - categorical_accuracy: 0.9740 - mean_squared_error: 0.0040 - val_loss: 0.6025 - val_acc: 0.8963 - val_categorical_accuracy: 0.8963 - val_mean_squared_error: 0.0177\n",
      "Epoch 47/50\n",
      "2690/2690 [==============================] - 4s - loss: 0.0702 - acc: 0.9773 - categorical_accuracy: 0.9773 - mean_squared_error: 0.0033 - val_loss: 0.6030 - val_acc: 0.8997 - val_categorical_accuracy: 0.8997 - val_mean_squared_error: 0.0181\n",
      "Epoch 48/50\n",
      "2690/2690 [==============================] - 4s - loss: 0.0609 - acc: 0.9796 - categorical_accuracy: 0.9796 - mean_squared_error: 0.0030 - val_loss: 0.7384 - val_acc: 0.8863 - val_categorical_accuracy: 0.8863 - val_mean_squared_error: 0.0199\n",
      "Epoch 49/50\n",
      "2690/2690 [==============================] - 4s - loss: 0.1057 - acc: 0.9699 - categorical_accuracy: 0.9699 - mean_squared_error: 0.0050 - val_loss: 0.5555 - val_acc: 0.8997 - val_categorical_accuracy: 0.8997 - val_mean_squared_error: 0.0172\n",
      "Epoch 50/50\n",
      "2690/2690 [==============================] - 4s - loss: 0.0993 - acc: 0.9673 - categorical_accuracy: 0.9673 - mean_squared_error: 0.0051 - val_loss: 0.3928 - val_acc: 0.9197 - val_categorical_accuracy: 0.9197 - val_mean_squared_error: 0.0134\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f373e954910>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "# input: 100x100 images with 3 channels -> (3, 100, 100) tensors.\n",
    "# this applies 32 convolution filters of size 3x3 each.\n",
    "K.set_image_dim_ordering('th')\n",
    "\n",
    "model.add(Convolution2D(32, 3, 3, border_mode='valid', input_shape=(3, 70, 70)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Convolution2D(32, 3, 3))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Convolution2D(32, 3, 3))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Convolution2D(64, 3, 3, border_mode='valid', input_shape=(3, 70, 70)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Convolution2D(64, 3, 3))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Convolution2D(64, 3, 3))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Convolution2D(128, 3, 3, border_mode='valid', input_shape=(3, 70, 70)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Convolution2D(128, 3, 3))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Convolution2D(128, 3, 3))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "# # Note: Keras does automatic shape inference.\n",
    "# model.add(Dense(256))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "adam = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "sgd = SGD(lr=0.0001, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "earlyStopping=EarlyStopping(monitor='val_loss', patience=0, verbose=0, mode='auto')\n",
    "model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy', 'categorical_accuracy', 'mean_squared_error'])\n",
    "model.fit(train_images, train_labels2, batch_size=32, nb_epoch=50, validation_split=0.1, validation_data=None)\n",
    "# callbacks=[earlyStopping]\n",
    "# model.fit(train_images, train_labels2, batch_size=32, nb_epoch=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save('mod_adam.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2976/2989 [============================>.] - ETA: 0s"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>row_0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>805</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>248</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>602</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>130</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>580</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>86</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>188</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>184</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0    0    1   2    3   4    5    6   7    8    9\n",
       "row_0                                               \n",
       "0      805    1  14    0   0    0    1   1    2    0\n",
       "1        0  248   0    0   0    0    0   0    0    0\n",
       "2        1    0  54    1   1    0    0   1    0    0\n",
       "3        0    0   1  602   1    2    0   0    0    0\n",
       "4        0    0   0    0  70    0    0   0    0    0\n",
       "5        0    2   0    1   0  130    0   0    0    0\n",
       "6        1    0   0    2   0    0  580   0    0    0\n",
       "7        0    0   0    0   0    0    0  86    2    0\n",
       "8        2    0   2    1   0    0    0   0  188    0\n",
       "9        0    0   0    0   1    1    0   0    0  184"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat = model.predict_classes(train_images)\n",
    "pd.crosstab(y_hat, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_images, test_labels = get_data_sampler(\"September_1_total_non_overlap\", train=False)\n",
    "model = load_model('mod_adam.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_images = test_images.transpose((0,3,1,2))\n",
    "enc = OneHotEncoder()\n",
    "enc.fit(test_labels[:,None])\n",
    "test_labels2=enc.transform(test_labels[:,None]).toarray()\n",
    "test_images.shape\n",
    "test_labels2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "736/748 [============================>.] - ETA: 0s"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>row_0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>195</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>138</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>141</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0    0   1  2    3  4   5    6   7   8   9\n",
       "row_0                                         \n",
       "0      195   1  7    0  0   0    3   2   0   1\n",
       "1        0  61  0    1  0   2    0   0   0   0\n",
       "2        4   0  5    5  1   0    0   0   1   1\n",
       "3        0   0  4  138  7   3    0   0   0   0\n",
       "4        0   0  1    0  9   0    0   0   0   0\n",
       "5        0   1  0    2  0  28    0   0   0   0\n",
       "6        3   0  0    0  0   0  141   0   0   0\n",
       "7        0   0  0    0  1   0    0  20   1   1\n",
       "8        1   0  1    4  0   0    0   0  46   0\n",
       "9        0   0  0    2  0   0    1   0   0  43"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat_t = model.predict_classes(test_images)\n",
    "pd.crosstab(y_hat_t, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "736/748 [============================>.] - ETA: 0s"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.35676533302521324,\n",
       " 0.91711229978398201,\n",
       " 0.91711229978398201,\n",
       " 0.013077612099720833]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_images, test_labels2, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['loss', 'acc', 'categorical_accuracy', 'mean_squared_error']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.metrics_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot(model, to_file='model_adam_pic.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
